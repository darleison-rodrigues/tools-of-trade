{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "992db3f7",
   "metadata": {},
   "outputs": [],
   "source": [
    "# 01 - Data Extraction and Cleaning\n",
    "\n",
    "# This notebook guides you through the process of extracting raw text from various file types (TXT, PDF, code) and performing initial cleaning.\n",
    "\n",
    "# Objective:\n",
    "# - Read files from `data/raw/texts/`, `data/raw/pdfs/`, and `data/raw/code/`.\n",
    "# - Extract text content using appropriate libraries (PyMuPDF, pdfplumber, pytesseract for OCR).\n",
    "# - Perform basic text cleaning (e.g., removing extra whitespace, handling line breaks).\n",
    "# - Save the extracted and cleaned documents with metadata into `data/processed/extracted_raw_documents.jsonl`.\n",
    "\n",
    "# Instructions:\n",
    "# 1. Ensure raw data is in place: Place your `.txt` files in `data/raw/texts/`, `.pdf` files in `data/raw/pdfs/`, and code files in `data/raw/code/`.\n",
    "# 2. Run `ingest_data.py`: You can execute the script directly from your terminal:\n",
    "#    python scripts/ingest_data.py\n",
    "#    # Or, if you need OCR for scanned PDFs:\n",
    "#    # python scripts/ingest_data.py --use_ocr_for_pdfs True\n",
    "# 3. Inspect output: Check the contents of `data/processed/extracted_raw_documents.jsonl` to ensure proper extraction.\n",
    "\n",
    "# Code (Example of what you'd put here):\n",
    "\n",
    "# You would typically run the functions from scripts/ingest_data.py here\n",
    "# import sys\n",
    "# sys.path.append('scripts') # Add scripts directory to Python path\n",
    "# from ingest_data import ingest_raw_data_pipeline, PROJECT_ROOT, PROCESSED_DOCS_PATH\n",
    "# import json\n",
    "# import os\n",
    "\n",
    "# print(f\"Project root: {PROJECT_ROOT}\")\n",
    "\n",
    "# # Run the ingestion pipeline\n",
    "# extracted_docs = ingest_raw_data_pipeline(use_ocr_for_pdfs=False) # Set to True if you need OCR\n",
    "\n",
    "# # Display a sample of extracted documents\n",
    "# if extracted_docs:\n",
    "#     print(f\"\\nSample of extracted document (first 500 chars of content):\")\n",
    "#     print(json.dumps(extracted_docs[0], indent=2)[:500] + \"...\")\n",
    "# else:\n",
    "#     print(\"No documents extracted.\")\n",
    "\n",
    "# # You can also manually inspect the JSONL file\n",
    "# # with open(PROCESSED_DOCS_PATH, 'r', encoding='utf-8') as f:\n",
    "# #     for i, line in enumerate(f):\n",
    "# #         if i < 2: # Print first 2 lines\n",
    "# #             print(json.loads(line))\n",
    "# #         else:\n",
    "# #             break"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
